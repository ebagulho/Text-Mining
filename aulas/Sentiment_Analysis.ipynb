{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Existem já um conjunto de bibliotecas que permitem classificar um pedaço de texto quanto ao sentimento. Uma dessas bibliotecas é a \"textblob\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[\"The movie was good.\", \n",
    "    \"The movie was not good.\",\n",
    "    \"I really think this product sucks.\",\n",
    "    \"Really great product.\",\n",
    "    \"I don't like this product\"]\n",
    "for t in texts:\n",
    "    print(t, \"==>\", TextBlob(t).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code assumes that the text is already split into sentences, which may not be the case of texts comming from sources, such as *web pages* or *blogs*. An alternate solution would be to give the whole text to `textblob` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=TextBlob(\"\"\"The movie was good. The movie was not good. I really think this product sucks.\n",
    "Really great product. I don't like this product\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in text.sentences:\n",
    "    print(\"=>\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in text.sentences:\n",
    "    print(s, \"==> \", s.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our own classifier\n",
    "Lets use [Sentiment Polarity Dataset 2.0](https://www.cs.cornell.edu/people/pabo/movie-review-data/), included in the `NLTK` library.<Br>\n",
    "It consists of 1000 positive and 1000 negative processed reviews. Introduced in Pang/Lee ACL 2004. Released June 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "print(\"The corpus contains %d reviews\"% len(mr.fileids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mr.fileids()[995:1005]: # Reviews 995 to 1005\n",
    "    print(i, \"==>\", i.split('/')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the content of one of these reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mr.raw(mr.fileids()[995]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the frequency of each word in the document ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "FreqDist(mr.raw(mr.fileids()[1]).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the most frequent words in the corpus"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wordfreq = FreqDist()\n",
    "for i in mr.fileids():\n",
    "    wordfreq += FreqDist(w.lower() for w in mr.raw(i).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code has flaws because split() is a very basic way of finding the words. Let's use `word_tokenize()` or `mr.words()` instead..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordfreq = FreqDist()\n",
    "for i in mr.fileids():\n",
    "    wordfreq += FreqDist(w.lower() for w in mr.words(i))\n",
    "print(wordfreq)\n",
    "pprint(wordfreq.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop words and punctuation are causing trouble, lets remove them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "wordfreq = FreqDist()\n",
    "for i in mr.fileids():\n",
    "    wordfreq += FreqDist(w.lower() for w in mr.words(i) if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "print(wordfreq)\n",
    "pprint(wordfreq.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets shuffle the documents, otherwise they will remain sorted [\"neg\", \"neg\" ... \"pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "docnames=mr.fileids()\n",
    "random.shuffle(docnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split each document into words ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[]\n",
    "for i in docnames:\n",
    "    y = i.split('/')[0]\n",
    "    documents.append( ( mr.words(i) , y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our documents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for docs in documents[:5]:\n",
    "    print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets produce the final document representation, in the form of a Frequency Distribution ...\n",
    "\n",
    "First, without stop words and punctuation ... (you could use other technique, such as IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "docrep=[]\n",
    "for words,tag in documents:\n",
    "    features = FreqDist(w for w in words if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "    docrep.append( (features, tag) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our documents again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docrep[:5]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK classifier: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our training and test sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtrain = int(len(documents) * 80 / 100)  # number of training documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = docrep[:numtrain], docrep[numtrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier as nbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nbc.train(train_set)\n",
    "print(\"Accuracy:\", nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma de avaliar a Accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import scores\n",
    "test_ref = [tag for doc,tag in test_set]\n",
    "test_pred = classifier.classify_many([doc for doc,tag in test_set])\n",
    "print(\"Accuracy:\", scores.accuracy(test_pred, test_ref) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with vocabulary selection ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "selected_features=[w for w,f in wordfreq.most_common(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_freq=FreqDist()\n",
    "for wordsf, t in docrep:\n",
    "    features_freq += wordsf\n",
    "features_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features=[f for f,ntimes in features_freq.most_common(500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the word *frequency* in each document... (after executing, go back and test the performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [({w:f for w,f in wordsf.items() if w in selected_features}, tag) for wordsf,tag in docrep[:numtrain]]\n",
    "test_set = [({w:f for w,f in wordsf.items() if w in selected_features}, tag) for wordsf,tag in docrep[numtrain:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each one of the *selected_features*, use its frequency in each document... (after executing, go back and test the performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [({f:wordsf[f] for f in selected_features}, tag) for wordsf,tag in docrep[:numtrain]]\n",
    "test_set = [({f:wordsf[f] for f in selected_features}, tag) for wordsf,tag in docrep[numtrain:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie um novo modelo com esta nova representação e avalie o seu desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nbc.train(train_set)\n",
    "print(\"Accuracy:\", nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with part-of-speech TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"time flies like an arrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag([\"he\", \"flies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(documents[0][0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "docrep=[]\n",
    "for words,tag in documents:\n",
    "    features = FreqDist(\"%s_%s\"%(w,p) for w,p in nltk.pos_tag(words) if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "    docrep.append( (features, tag) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docrep[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#pos_features = FreqDist(chain(*[doc for doc,tag in pos_docs]))\n",
    "#sel_pos_features=sorted(pos_features, key=pos_features.__getitem__, reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posfeatures_freq=FreqDist()\n",
    "for ff, t in docrep:\n",
    "    posfeatures_freq += ff\n",
    "posfeatures_freq.most_common(10)\n",
    "selected_posfeatures=[f for f,freq in posfeatures_freq.most_common(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [({f:ff[f] for f in selected_posfeatures}, tag) for ff,tag in docrep[:numtrain]]\n",
    "test_set = [({f:ff[f] for f in selected_posfeatures}, tag) for ff,tag in docrep[numtrain:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the results again ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nbc.train(train_set)\n",
    "print(\"Accuracy:\", nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "Calcule o desempenho do TextBlob usando o mesmo conjunto de teste.\n",
    "\n",
    "<!--\n",
    "y=[]\n",
    "y_pred=[]\n",
    "for fn in docnames[numtrain:]:\n",
    "    y.append(fn.split('/')[0])\n",
    "    if TextBlob(mr.raw(fn)).sentiment.polarity >= 0:\n",
    "        y_pred.append(\"pos\")\n",
    "    else:\n",
    "        y_pred.append(\"neg\")\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y, y_pred))\n",
    "-->"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now much faster, using some useful scikit-learn functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assuming that documents are shuffled\n",
    "Go back to the shuffle section, and make sure `docnames` contain a shuffled list of documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[]\n",
    "tags = []\n",
    "for doc in docnames:\n",
    "    documents.append(mr.raw(doc))\n",
    "    tags.append( doc.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(tags[i], documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtrain = int(len(documents) * 80 / 100)  # number of training documents\n",
    "train_documents, test_documents = documents[:numtrain], documents[numtrain:]\n",
    "train_tags, test_tags = tags[:numtrain], tags[numtrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_X = vectorizer.fit_transform(train_documents)\n",
    "test_X = vectorizer.transform(test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(train_X, train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metrics.accuracy_score(test_tags, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
