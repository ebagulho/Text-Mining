{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Lets use [Sentiment Polarity Dataset 2.0](https://www.cs.cornell.edu/people/pabo/movie-review-data/), included in the `NLTK` library.<Br>\n",
    "It consists of 1000 positive and 1000 negative processed reviews. Introduced in Pang/Lee ACL 2004. Released June 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus contains 2000 reviews\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "print(\"The corpus contains %d reviews\"% len(mr.fileids()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets shuffle the documents, otherwise they will remain sorted [\"neg\", \"neg\" ... \"pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "docnames=mr.fileids()\n",
    "random.shuffle(docnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do it using some useful scikit-learn functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assuming that documents are shuffled\n",
    "Go back to the shuffle section, and make sure `docnames` contain a shuffled list of documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[]\n",
    "tags = []\n",
    "for doc in docnames:\n",
    "    documents.append(mr.raw(doc))\n",
    "    tags.append( doc.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg the second serial-killer thriller of the month is just awful . \n",
      "oh , it starts deceptively okay , with a handful of intriguing characters and some solid location work . \n",
      "after a baby-sitter gets gutted in the suit- ably spooky someone's-in-the-house prologue , parallel stories unfold , the first involving a texas sheriff ( r . lee emery ) , a gruesome double murder , and the arrival of a morose fbi agent ( dennis quaid ) on the eve of voting for the local lawman's reelection . \n",
      "the second pairs a hitch- hiker ( jared leto ) with a friendly former railroad worker ( danny glover ) . \n",
      "they're headed west , toward the rockies and away from the murder scene . \n",
      "which one is the killer ? \n",
      "well , it doesn't really matter , 'cause when writer/first-time director jeb stuart ( die hard ) finally spills the beans , you won't take his choice seriously anyway . \n",
      "the whole thing goes south about an hour in , with the tale taking hairpin turns that i certainly couldn't follow . \n",
      "and through the whole thing there's quaid , playing with the most intense monotony this side of steven sea- gal . \n",
      "i guess i'm glad that i didn't walk out-- there's some nice train stuff at the end and a fun nod to dr . \n",
      "strangelove . \n",
      "\n",
      "pos time bandits , from director terry gilliam , is a very different fantasy action/adventure movie about a group of time-traveling dwarves , led by randall ( david rappaport ) , who have stolen a map of the universe . \n",
      "this map contains time hole , that , if exploited , enable the men to travel back and forth through time . \n",
      "the supreme being of the universe ( ralph richardson ) is the former employer of these treasure-seeking bandits , and he wishes desperately to regain the map . . \n",
      "during the travels , he appears as a ghostly face , demanding that they return the map that they have stolen . \n",
      "but , according to randall , they are just \" borrowing \" it . \n",
      "kevin , a young boy who seems quite bored with his life , is unexpectedly brought into the schemes of the little men when they appear in his room , which has a portal for time traveling . \n",
      "he joins up with the men and becomes part of their gang , following them on their robberies . \n",
      "their first victim is napoleon ( ian holm ) , whom they rob during a battle that he is commanding . \n",
      "from here , the group travels to the middle ages , meeting up with robin hood himself . \n",
      "eventually , kevin is separated from the group and travels to an egyptian time where he is taken in by king agamemnon , played by sean connery . \n",
      "kevin accidentally saved the king's life , and the king wishes to have kevin as his son . \n",
      "but the group of bandits find kevin and transport onto the deck of the titanic . \n",
      "meanwhile , the evil genius ( david warner ) is watching the group from fortress of ultimate darkness , attempting to find a way in order to bring the men , and the map , to him . \n",
      "when randall learns of the fortress of ultimate darkness , which supposedly contains \" the most fabulous object in the world \" , the dollar signs seemingly appear on his eyes , as he is convinced that they must travel there . \n",
      "once inside the fortress of ultimate darkness , it is unclear as to if any of the men will make it out alive . \n",
      "time bandits is a fantastically made film that caters to the imagination of anyone . \n",
      "with a terrific soundtrack , courtesy of george harrison , whom also was an executive producer , time bandits is sure to be a very surrealistic , time-traveling adventure with unforgettable characters that is sure to entertain anyone . \n",
      "terry gilliam , however , does not utilize that greatly his trademark ability in moviemaking during this film , although this does not affect the film that greatly . \n",
      "and finally , if you liked labyrinth , you'll love time bandits . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tags[i], documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtrain = int(len(documents) * 80 / 100)  # number of training documents\n",
    "train_documents, test_documents = documents[:numtrain], documents[numtrain:]\n",
    "train_tags, test_tags = tags[:numtrain], tags[numtrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_X = vectorizer.fit_transform(train_documents)\n",
    "test_X = vectorizer.transform(test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adrian', 'adrianne', 'adrien', 'adrienne', 'adrift', 'adroit', 'adroitly', 'ads', 'adulation', 'adult', 'adulterer', 'adulterous', 'adultery', 'adulthood', 'adultrous', 'adults', 'advance', 'advanced', 'advancement', 'advances', 'advancing', 'advantage', 'advantaged', 'advantages', 'advent', 'adventure', 'adventurer', 'adventures', 'adventurous', 'adversarial', 'adversaries', 'adversary', 'adverse', 'adversely', 'adversity', 'advertise', 'advertised', 'advertisement', 'advertisements', 'advertiser', 'advertising', 'advertisment', 'advice', 'advil', 'advisable', 'advise', 'advised', 'adviser', 'advisers', 'advises', 'advising', 'advisor', 'advisors', 'advocate', 'advocated', 'advocates', 'advocating', 'aerial', 'aerosmith', 'aerospace', 'aesthetic', 'aesthetically', 'aesthetics', 'afa', 'afar', 'afeminite', 'affability', 'affable', 'affair', 'affairs', 'affay', 'affect', 'affectations', 'affected', 'affecting', 'affection', 'affectionate', 'affectionately', 'affections', 'affects', 'afficianados', 'affiliate', 'affiliated', 'affiliations', 'affinity', 'affirm', 'affirmation', 'affirmative', 'affirming', 'affleck', 'afflicted', 'affliction', 'affluent', 'afford', 'affordable', 'afforded', 'affords', 'affront', 'aficionado', 'aficionados']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 36284) (400, 36284)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_X, train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.807\n"
     ]
    }
   ],
   "source": [
    "score = sklearn.metrics.accuracy_score(test_tags, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como usar o classificador para processar frases novas?\n",
    "\n",
    "1. É necessário fazer exatamente o mesmo processamento que foi anteriormente feito ao conjunto de teste.\n",
    "2. Aplicar o classificador ao resultado desses processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frases = [\"I love movies very much\", \n",
    "          \"I hate my stupid life\"]\n",
    "frases_X = vectorizer.transform(frases)\n",
    "classifier.predict(frases_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
