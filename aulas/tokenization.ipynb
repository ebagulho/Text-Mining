{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento básico de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso esteja a utilizar o google colab, deve seguir as instruções disponíveis no moodle\n",
    "e correr a célula seguinte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto=\"\"\"Espirais do Polo Norte de Marte mostradas em detalhe\n",
    "A Agência Espacial Europeia pegou em 32 \"tiras\" de órbitas registadas pela sonda Mars Express entre 2004 e 2010 e criou um \"mosaico\" que cobre uma área de cerca de um milhão de quilómetros quadrados.\n",
    "\"Esta informação é muito importante para perceber como evoluiu o clima no planeta à medida que a sua inclinação e órbita variavam ao longo de centenas ou mesmo milhares de anos\", refere a ESA.\n",
    "A Estação Espacial Europeia acredita que são os ventos fortes da região os responsáveis por moldarem o gelo, já que sopram desde a parte central mais alta, até às margens inferiores e fazem redemoinhos empurrados pela mesma força que faz os furacões girarem na Terra.\n",
    "Ainda que a calote polar seja um \"elemento permanente\", durante o inverno as temperaturas são tão baixas que 30% do dióxido de carbono da atmosfera do planeta precipita-se sobre a mesma, acrescentando-lhe uma \"capa extra\" de até um metro de espessura.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantas palavras diferentes podemos encontrar neste texto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Como identificar os *tokens* de um texto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que há tokens que fazem pouco sentido: e.g. `'\"mosaico\"'`, `'ESA.'`, ...\n",
    "\n",
    "Uma forma de resolver o problema poderá envolver processamento do texto, por exemplo separando os carateres `\"` e `.` das palavras à sua volta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = re.sub('([\\.\\\"])', ' \\\\1 ', texto)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto2 = re.sub('([\\.\\\"])', ' \\\\1 ', texto)\n",
    "texto2 = re.sub(' +', ' ', texto2)\n",
    "print(texto2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim, já será possivel obter uma segmentação mais interessante..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto2.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressões regulares\n",
    "\n",
    "As expresssões regulares têm inúmeras aplicações: filtragem, obtenção de padões, etc.\n",
    "\n",
    "Options:\n",
    "- `re.I`: perform case-insensitive matching\n",
    "- `re.MULTILINE`: When specified, the pattern character '^' matches at the beginning of the string and at the beginning of each line (immediately following each newline)\n",
    "- `re.DOTALL`: Make the '.' special character match any character at all, including a newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall(\"[A-Z][a-z]+\", texto2, re.MULTILINE)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Façamos agora algum pré-processamento básico inicial para juntar as várias frases numa única linha e transformar tudo em minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto2 = re.sub(r'[\\n\\r]', \"\", texto2).lower()\n",
    "print(texto2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois do pré-processamento inicial, calcular a frequência de cada token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "freq=collections.Counter(texto2.split())\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq[\"que\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agora usando o NLTK\n",
    "Observe que para além dos sinais de pontuação, tais como \".\" e \",\", as aspas também podem representar um problema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras=nltk.word_tokenize(texto)\n",
    "print(palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização de Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesma solução não produz um bom resultado quando aplicada, por exemplo, a tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\n",
    "\n",
    "print(nltk.word_tokenize(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "mytkzr = TweetTokenizer()\n",
    "print(mytkzr.tokenize(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro exemplo ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"Olá @manuel_silva, a cadeira de #text-mining rulezzzz. :)\"\n",
    "print(mytkzr.tokenize(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de processamento de um ficheiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd /content/drive/MyDrive/Iscte/TM/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "f=gzip.open(\"../data/pt/tsf.selecionado/not_4180883.gz\", \"rt\", encoding=\"utf-8\")\n",
    "doc=f.readlines()\n",
    "f.close()\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\\n\".join(doc)\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "palavras=nltk.word_tokenize(texto)\n",
    "print(\" | \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
