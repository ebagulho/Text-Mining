{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Word2vec and Glove\n",
    "\n",
    "Ver também:\n",
    "\n",
    "* [Deep Learning, NLP, and Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n",
    "* [Vector Space Models for the Digital Humanities](http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim\n",
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando um modelo GloVe pré-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora proceder à leitura de um modelo já treinado.\n",
    "\n",
    "Note que esta operação demora alguns segundos a concluir a sua execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading local version of the model\n",
      "Downloading latest version from kaggle\n",
      "Path to dataset files: /Users/fmmb/.cache/kagglehub/datasets/watts2/glove6b50dtxt/versions/1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('Downloading local version of the model')\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(\"../data/en/glove.6B.50d.txt.gensim.gz\", binary=False)\n",
    "except:\n",
    "    print('Downloading latest version from kaggle')\n",
    "    import kagglehub\n",
    "\n",
    "    path = kagglehub.dataset_download(\"watts2/glove6b50dtxt\")\n",
    "\n",
    "    print(\"Path to dataset files:\", path)\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(path + \"/glove.6B.50d.txt\", binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8860338"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sadness', 0.804125964641571),\n",
       " ('passion', 0.7860099077224731),\n",
       " ('sorrow', 0.7810678482055664),\n",
       " ('delight', 0.7686560153961182),\n",
       " ('happiness', 0.7658459544181824),\n",
       " ('grief', 0.7552624344825745),\n",
       " ('pride', 0.752964973449707),\n",
       " ('tears', 0.7461303472518921),\n",
       " ('love', 0.7359328866004944),\n",
       " ('affection', 0.7240350842475891)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['joy'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', 0.8694775104522705),\n",
       " ('look', 0.8646224141120911),\n",
       " ('well', 0.8602237701416016),\n",
       " ('come', 0.8595820665359497),\n",
       " ('so', 0.8569967150688171),\n",
       " ('how', 0.8522789478302002),\n",
       " ('little', 0.8518632054328918),\n",
       " (\"n't\", 0.8507798314094543),\n",
       " ('big', 0.8480952382087708),\n",
       " ('everything', 0.847752571105957)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['like'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lovely', 0.9210881590843201),\n",
       " ('gorgeous', 0.893486499786377),\n",
       " ('wonderful', 0.8296379446983337),\n",
       " ('charming', 0.8249218463897705),\n",
       " ('beauty', 0.8014684915542603),\n",
       " ('elegant', 0.7744168639183044),\n",
       " ('looks', 0.7581824660301208),\n",
       " ('love', 0.7359940409660339),\n",
       " ('graceful', 0.7350156307220459),\n",
       " ('magnificent', 0.7346351146697998)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['beautiful'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['france', \"lisbon\"],  negative=['portugal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['france', \"lisbon\"], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de treino de modelo word2vec\n",
    "\n",
    "Inspirado em [Word2vec Tutorial](https://rare-technologies.com/word2vec-tutorial/) by Radim Rehurek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = [\"o joão correu durante o dia\",\n",
    "            \"o iscte estava fechado durante o dia\",\n",
    "            \"falei muito no dia de ontem\",\n",
    "            \"o dia foi bom e correu bem\",\n",
    "            \"no dia de todos os santos\",\n",
    "            \"o dia no parque foi bom\"]\n",
    "tokens = [ t.split() for t in texto ]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec on the tokens\n",
    "model2 = gensim.models.Word2Vec(tokens, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.most_similar(\"dia\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
