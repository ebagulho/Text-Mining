{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our own classifier\n",
    "Lets use [Sentiment Polarity Dataset 2.0](https://www.cs.cornell.edu/people/pabo/movie-review-data/), included in the `NLTK` library.<Br>\n",
    "It consists of 1000 positive and 1000 negative processed reviews. Introduced in Pang/Lee ACL 2004. Released June 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "print(\"The corpus contains %d reviews\"% len(mr.fileids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mr.fileids()[995:1005]: # Reviews 995 to 1005\n",
    "    print(i, \"==>\", i.split('/')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the content of one of these reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mr.raw(mr.fileids()[995]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking wich are the most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the frequency of each word in the document ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "FreqDist(mr.raw(mr.fileids()[1]).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the most frequent words in the corpus"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wordfreq = FreqDist()\n",
    "for i in mr.fileids():\n",
    "    wordfreq += FreqDist(w.lower() for w in mr.raw(i).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code has flaws because split() is a very basic way of finding the words. Let's use `word_tokenize()` or `mr.words()` instead..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = FreqDist()\n",
    "for i in mr.fileids():\n",
    "    wordfreq += FreqDist(w.lower() for w in word_tokenize(mr.raw(i)))\n",
    "print(wordfreq)\n",
    "print(wordfreq.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop words and punctuation are causing trouble, lets remove them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "wordfreq = FreqDist()\n",
    "for i in mr.fileids():\n",
    "    wordfreq += FreqDist(w.lower() for w in word_tokenize(mr.raw(i)) \n",
    "        if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "print(wordfreq)\n",
    "print(wordfreq.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets shuffle the documents, otherwise they will remain sorted [\"neg\", \"neg\" ... \"pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read each document into words ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docnames=mr.fileids()\n",
    "random.shuffle(docnames)\n",
    "documents=[]\n",
    "for i in docnames:\n",
    "    y = i.split('/')[0]\n",
    "    documents.append( (mr.raw(i), y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our documents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for docs in documents[0:2]:\n",
    "    print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets produce the final document representation, in the form of a Frequency Distribution ...\n",
    "\n",
    "First, without stop words and punctuation ... (you could use other technique, such as IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "docrep=[]\n",
    "for text,tag in documents:\n",
    "    features = FreqDist(w for w in word_tokenize(text) \n",
    "                        if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "    docrep.append( (features, tag) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our documents again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docrep[:5]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK classifier: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our training and test sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtrain = int(len(documents) * 80 / 100)  # number of training documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = docrep[:numtrain], docrep[numtrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier as nbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nbc.train(train_set)\n",
    "print(\"Accuracy: {:.3f}\".format( nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma (mais genérica) de avaliar a Accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import scores\n",
    "test_ref = [tag for doc,tag in test_set]\n",
    "test_pred = classifier.classify_many([doc for doc,tag in test_set])\n",
    "print(\"Accuracy: {:.3f}\".format(scores.accuracy(test_pred, test_ref) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar as próximas etapas, vamos criar um procedimento que faz o treino e a avaliação logo de seguida...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier as nbc\n",
    "from nltk.metrics import scores\n",
    "\n",
    "def train_and_evaluate(train_set, test_set):\n",
    "    classifier = nbc.train(train_set)\n",
    "    test_ref = [tag for doc,tag in test_set]\n",
    "    test_pred = classifier.classify_many([doc for doc,tag in test_set])\n",
    "    print(\"Accuracy: {:.3f}\".format(scores.accuracy(test_pred, test_ref) ) )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's select only the most relevant words ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts=FreqDist()\n",
    "for doc_feature_counts, _ in train_set:\n",
    "    feature_counts += doc_feature_counts\n",
    "print(feature_counts.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features=[f for f,ntimes in feature_counts.most_common(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the word *frequency* in each document... (after executing, test the performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs2features(docs, selected_features):\n",
    "    features = []\n",
    "    for doc_feature_counts, tag in docs:\n",
    "        features.append(({w:f for w,f in doc_feature_counts.items() if w in selected_features}, tag))\n",
    "    return features\n",
    "\n",
    "train_set = docs2features(docrep[:numtrain], selected_features)\n",
    "test_set = docs2features(docrep[numtrain:], selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each one of the *selected_features*, use its frequency in each document... (after executing, go back and test the performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs2features(docs, selected_features):\n",
    "    features = []\n",
    "    for doc_feature_counts, tag in docs:\n",
    "        features.append(({f:doc_feature_counts[f] for f in selected_features}, tag))\n",
    "    return features\n",
    "\n",
    "train_set = docs2features(docrep[:numtrain], selected_features)\n",
    "test_set = docs2features(docrep[numtrain:], selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with part-of-speech TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"time flies like an arrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag([\"he\", \"flies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(word_tokenize(documents[0][0]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "docrep=[]\n",
    "for text,tag in documents:\n",
    "    features = FreqDist(\"%s_%s\"%(w,p) for w,p in nltk.pos_tag(word_tokenize(text)) \n",
    "                        if w.lower() not in stopw and w.lower() not in string.punctuation)\n",
    "    docrep.append( (features, tag) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docrep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts=FreqDist()\n",
    "for doc_feature_counts, t in docrep:\n",
    "    feature_counts += doc_feature_counts\n",
    "feature_counts.most_common(10)\n",
    "selected_features=[f for f,freq in feature_counts.most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs2features(docs, selected_features):\n",
    "    features = []\n",
    "    for doc_feature_counts, tag in docs:\n",
    "        features.append(({f:doc_feature_counts[f] for f in selected_features}, tag))\n",
    "    return features\n",
    "\n",
    "train_set = docs2features(docrep[:numtrain], selected_features)\n",
    "test_set = docs2features(docrep[numtrain:], selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the results again ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = train_and_evaluate(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "Calcule o desempenho do TextBlob usando o mesmo conjunto de teste.\n",
    "\n",
    "<!--\n",
    "y=[]\n",
    "y_pred=[]\n",
    "for fn in docnames[numtrain:]:\n",
    "    y.append(fn.split('/')[0])\n",
    "    if TextBlob(mr.raw(fn)).sentiment.polarity >= 0:\n",
    "        y_pred.append(\"pos\")\n",
    "    else:\n",
    "        y_pred.append(\"neg\")\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y, y_pred))\n",
    "-->"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
