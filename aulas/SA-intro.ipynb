{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimento - Exemplos introdutórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalmente apenas necessário se usar o google colab\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere os seguintes textos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = [ \"The movie was good.\",\n",
    "          \"I hate the movie\",\n",
    "          \"The movie was not good.\",\n",
    "          \"I really think this product sucks.\",\n",
    "          \"Really great product.\",\n",
    "          \"I don't like this product\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, vamos aplicar duas estratégias básicas para atribuir o sentimento a um texto.\n",
    "1. Aplicar uma ferramenta já treinada\n",
    "2. aplicar um léxico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aplicação de uma ferramenta pré-treinada\n",
    "Existem já um conjunto de bibliotecas que permitem classificar um pedaço de texto quanto ao sentimento. Uma dessas bibliotecas é a \"textblob\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in textos:\n",
    "    print(t, \"==>\", TextBlob(t).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code assumes that the text is already split into sentences, which may not be the case of texts comming from sources, such as *web pages* or *blogs*. An alternate solution would be to give the whole text to `textblob` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto=TextBlob(\"\"\"The movie was good. The movie was not good. I really think this product sucks.\n",
    "Really great product. I don't like this product\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in texto.sentences:\n",
    "    print(\"=>\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in texto.sentences:\n",
    "    print(s, \"==> \", s.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação de um léxico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do léxico de sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"../data/en/NCR-lexicon.csv\", encoding=\"utf-8\")\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/fmmb/Text-Mining/main/data/NRC-lexicon.csv\", encoding=\"utf-8\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index(\"English\", inplace=True)\n",
    "lex1 = data[\"Positive\"] - data[\"Negative\"]\n",
    "lex1.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por vezes, os dataframes e as séries são pouco eficientes e, neste caso, a informação pode ser facilmente representada por um simples dicionário, o que tornará o nosso código muito mais rápido..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex2 = lex1.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como usar este lexico para processar um texto? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'I hate to say goodbye but I love chocolate'\n",
    "soma = 0\n",
    "for w in texto.split():\n",
    "    soma = soma + lex2.get(w, 0)\n",
    "    print(w, lex2.get(w, 0) )\n",
    "print(\"Soma:\" , soma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou melhor ainda, fazendo uma função..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimento(texto):\n",
    "    soma = 0\n",
    "    for w in texto.split():\n",
    "        soma = soma + lex2.get(w, 0)\n",
    "        #print(w, lex2.get(w, 0) )\n",
    "    #print(\"Soma:\" , soma)\n",
    "    if soma >= 0:\n",
    "        return \"POS\"\n",
    "    else:\n",
    "        return \"NEG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I hate to say goodbye but I love chocolate'\n",
    "sentimento(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for texto in textos:\n",
    "    print(sentimento(texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
